#!/usr/bin/env python3
"""
BBOT TUI - Self-installing terminal-based interface for browsing BBOT scan results

This script automatically sets up its own virtual environment and dependencies on first run.
Simply copy this file to any server and run it - no other setup required!
"""

import sys
import os
from pathlib import Path

# Required dependencies
DEPENDENCIES = [
    "textual>=0.47.0",
    "rich>=13.0.0",
    "psutil>=5.9.0",  # For detecting active scan processes (cross-platform)
]

def setup_environment():
    """Set up virtual environment and install dependencies"""
    script_path = Path(__file__).resolve()
    venv_dir = Path("~/.bbot_ui_venv").expanduser()
    marker_file = venv_dir / ".setup_complete"

    # Check if setup is already complete
    if marker_file.exists():
        # Setup already done, just use the venv
        if os.name == 'nt':  # Windows
            venv_python = venv_dir / "Scripts" / "python.exe"
        else:  # Unix/Linux/Mac
            venv_python = venv_dir / "bin" / "python"

        # Re-execute with venv python
        os.execv(str(venv_python), [str(venv_python), str(script_path)] + sys.argv[1:])

    print("=" * 60)
    print("BBOT TUI - First Run Setup")
    print("=" * 60)

    # Create virtual environment
    if not venv_dir.exists():
        print(f"\n[1/3] Creating virtual environment at {venv_dir}")
        import venv
        venv.create(venv_dir, with_pip=True)
        print("âœ“ Virtual environment created")

    # Determine venv python path
    if os.name == 'nt':  # Windows
        venv_python = venv_dir / "Scripts" / "python.exe"
        venv_pip = venv_dir / "Scripts" / "pip.exe"
    else:  # Unix/Linux/Mac
        venv_python = venv_dir / "bin" / "python"
        venv_pip = venv_dir / "bin" / "pip"

    # Upgrade pip and install dependencies
    print("\n[2/3] Installing dependencies...")
    import subprocess

    # Upgrade pip quietly
    subprocess.run(
        [str(venv_python), "-m", "pip", "install", "-q", "--upgrade", "pip"],
        check=True
    )

    # Install dependencies
    for dep in DEPENDENCIES:
        print(f"  - Installing {dep}")
        subprocess.run(
            [str(venv_pip), "install", "-q", dep],
            check=True
        )

    print("âœ“ All dependencies installed")

    # Create marker file to indicate setup is complete
    marker_file.touch()

    # Re-execute this script using the venv Python
    print(f"\n[3/3] Launching BBOT TUI...")
    print("=" * 60 + "\n")

    os.execv(str(venv_python), [str(venv_python), str(script_path)] + sys.argv[1:])

# Bootstrap: Check if we need to set up the environment
if __name__ == "__main__":
    script_path = Path(__file__).resolve()
    venv_dir = Path("~/.bbot_ui_venv").expanduser()
    marker_file = venv_dir / ".setup_complete"

    # Determine if we're running from the venv Python
    if os.name == 'nt':  # Windows
        venv_python = venv_dir / "Scripts" / "python.exe"
    else:  # Unix/Linux/Mac
        venv_python = venv_dir / "bin" / "python"

    is_venv_python = venv_python.exists() and Path(sys.executable).resolve() == venv_python.resolve()

    # If marker doesn't exist, run full setup
    if not marker_file.exists():
        setup_environment()
        sys.exit(0)  # Should never reach here due to execv, but just in case

    # If marker exists but we're not running from venv, switch to venv
    if marker_file.exists() and not is_venv_python:
        os.execv(str(venv_python), [str(venv_python), str(script_path)] + sys.argv[1:])

    # If we reach here, we're in the venv and ready to run

# ============================================================================
# Main Application Code (runs only after environment is set up)
# ============================================================================

import json
from typing import List, Dict, Any, Optional
from datetime import datetime

from textual.app import App, ComposeResult
from textual.containers import Container, Vertical, Horizontal, VerticalScroll
from textual.widgets import (
    Header,
    Footer,
    DataTable,
    Static,
    Button,
    Input,
    Label,
    Tree,
    TabbedContent,
    TabPane,
)
from textual.widgets.tree import TreeNode
from textual.binding import Binding
from textual.reactive import reactive
from textual.screen import Screen
from rich.syntax import Syntax
from rich.json import JSON
from rich.table import Table as RichTable
import zipfile
import shutil


# ============================================================================
# Archive Helper Functions
# ============================================================================

def create_archive(scan_path: Path) -> tuple[bool, str]:
    """
    Create a ZIP archive from a scan folder.

    Args:
        scan_path: Path to the scan directory to archive

    Returns:
        Tuple of (success, message)
        - success: True if archive created successfully, False otherwise
        - message: Error message if failed, success message if succeeded
    """
    try:
        archive_path = scan_path.parent / f"{scan_path.name}.zip"

        # Check if archive already exists
        if archive_path.exists():
            return (False, f"Archive already exists: {archive_path.name}")

        # Create ZIP archive
        with zipfile.ZipFile(archive_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            # Walk through all files in scan directory
            for root, dirs, files in os.walk(scan_path):
                for file in files:
                    file_path = Path(root) / file
                    # Calculate relative path for archive
                    arcname = file_path.relative_to(scan_path.parent)
                    zipf.write(file_path, arcname)

        # Verify archive integrity
        with zipfile.ZipFile(archive_path, 'r') as zipf:
            bad_file = zipf.testzip()
            if bad_file is not None:
                # Archive is corrupted
                archive_path.unlink()  # Delete bad archive
                return (False, f"Archive verification failed: {bad_file} is corrupted")

        # Archive is good, now delete the source folder
        shutil.rmtree(scan_path)

        return (True, f"Successfully archived to {archive_path.name}")

    except Exception as e:
        # Clean up incomplete archive if it exists
        if 'archive_path' in locals() and archive_path.exists():
            try:
                archive_path.unlink()
            except:
                pass
        return (False, f"Failed to create archive: {str(e)}")


def extract_archive(archive_path: Path) -> tuple[bool, str]:
    """
    Extract a ZIP archive back to a scan folder.

    Args:
        archive_path: Path to the ZIP archive

    Returns:
        Tuple of (success, message)
        - success: True if extracted successfully, False otherwise
        - message: Error message if failed, success message if succeeded
    """
    try:
        # Determine extraction path (remove .zip extension)
        if not archive_path.name.endswith('.zip'):
            return (False, "Not a ZIP file")

        scan_name = archive_path.name[:-4]  # Remove .zip
        extract_path = archive_path.parent / scan_name

        # Check if directory already exists
        if extract_path.exists():
            return (False, f"Directory already exists: {scan_name}")

        # Extract archive
        with zipfile.ZipFile(archive_path, 'r') as zipf:
            zipf.extractall(archive_path.parent)

        # Verify extraction by checking for output.json
        output_json = extract_path / "output.json"
        if not output_json.exists():
            # Extraction failed or invalid scan
            shutil.rmtree(extract_path)
            return (False, "Invalid scan archive: output.json not found")

        # Try to read first line to verify it's valid
        try:
            with open(output_json, 'r') as f:
                first_line = f.readline()
                json.loads(first_line)
        except:
            # output.json is corrupted
            shutil.rmtree(extract_path)
            return (False, "Invalid scan archive: output.json is corrupted")

        # Extraction successful, delete archive
        archive_path.unlink()

        return (True, f"Successfully restored {scan_name}")

    except Exception as e:
        # Clean up incomplete extraction if it exists
        if 'extract_path' in locals() and extract_path.exists():
            try:
                shutil.rmtree(extract_path)
            except:
                pass
        return (False, f"Failed to extract archive: {str(e)}")


def get_archive_stats(archive_path: Path) -> dict:
    """
    Get statistics from a ZIP archive without extracting it.

    Args:
        archive_path: Path to the ZIP archive

    Returns:
        Dictionary with keys: size, date, event_count, vuln_count, finding_count
        Returns empty dict on error
    """
    try:
        stat = archive_path.stat()

        stats = {
            'size': stat.st_size,
            'date': datetime.fromtimestamp(stat.st_mtime).strftime("%Y-%m-%d %H:%M"),
            'event_count': 0,
            'vuln_count': 0,
            'finding_count': 0,
        }

        # Try to read output.json from archive to get event counts
        try:
            with zipfile.ZipFile(archive_path, 'r') as zipf:
                # Find output.json in archive (should be scan_name/output.json)
                scan_name = archive_path.name[:-4]  # Remove .zip
                output_json_path = f"{scan_name}/output.json"

                if output_json_path in zipf.namelist():
                    # Get the compressed file info
                    file_info = zipf.getinfo(output_json_path)
                    uncompressed_size = file_info.file_size

                    with zipf.open(output_json_path, 'r') as f:
                        # For smaller files (<1MB), count exactly
                        if uncompressed_size < 1_000_000:
                            content = f.read().decode('utf-8', errors='ignore')
                            for line in content.split('\n'):
                                line = line.strip()
                                if not line:
                                    continue
                                try:
                                    event = json.loads(line)
                                    event_type = event.get("type", "")
                                    if event_type != "SCAN":
                                        stats['event_count'] += 1
                                    if event_type == "VULNERABILITY":
                                        stats['vuln_count'] += 1
                                    elif event_type == "FINDING":
                                        stats['finding_count'] += 1
                                except:
                                    continue
                        else:
                            # For larger files, estimate based on sampling
                            sample_size = 100000
                            content = f.read(sample_size).decode('utf-8', errors='ignore')

                            sample_events = 0
                            sample_vulns = 0
                            sample_findings = 0

                            for line in content.split('\n'):
                                line = line.strip()
                                if not line:
                                    continue
                                try:
                                    event = json.loads(line)
                                    event_type = event.get("type", "")
                                    if event_type != "SCAN":
                                        sample_events += 1
                                    if event_type == "VULNERABILITY":
                                        sample_vulns += 1
                                    elif event_type == "FINDING":
                                        sample_findings += 1
                                except:
                                    continue

                            # Estimate total based on sample ratio
                            ratio = uncompressed_size / sample_size
                            stats['event_count'] = int(sample_events * ratio)
                            stats['vuln_count'] = int(sample_vulns * ratio)
                            stats['finding_count'] = int(sample_findings * ratio)
        except:
            # If we can't read the archive, just return basic stats
            pass

        return stats

    except:
        return {}


class ScanData:
    """Parse and manage BBOT scan data"""

    def __init__(self, scan_path: Path):
        self.scan_path = scan_path
        self.scan_name = scan_path.name
        self.events: List[Dict[str, Any]] = []
        self.scan_info: Dict[str, Any] = {}
        self.preset_content: str = ""
        self.file_position: int = 0  # Track position in output.json for incremental reads
        self.file_handler_cache = None  # Cache for file handler check: (result, timestamp)
        self.cache_ttl = 5.0  # Cache results for 5 seconds
        self.load_events()
        self.load_preset()

    def load_events(self):
        """Load events from output.json"""
        json_file = self.scan_path / "output.json"
        if not json_file.exists():
            return

        with open(json_file, "r") as f:
            for line in f:
                line = line.strip()
                if line:
                    try:
                        event = json.loads(line)
                        if event.get("type") == "SCAN":
                            # Keep the LAST SCAN event (overwrite previous ones)
                            self.scan_info = event
                        else:
                            self.events.append(event)
                    except json.JSONDecodeError:
                        continue

        # Update file position
        try:
            self.file_position = json_file.stat().st_size
        except:
            pass

    def _check_file_open_psutil(self, file_path: Path) -> bool:
        """
        Check if file is open using psutil (native Python, cross-platform).
        Returns True if open, False if not, None if psutil unavailable.
        """
        try:
            import psutil
            file_path_str = str(file_path.resolve())

            # Iterate through all processes
            for proc in psutil.process_iter(['pid', 'name']):
                try:
                    # Check if process has the file open
                    for open_file in proc.open_files():
                        if open_file.path == file_path_str:
                            return True
                except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                    # Process ended or we don't have permission
                    continue

            return False
        except ImportError:
            # psutil not available
            return None
        except Exception:
            # Other error
            return None


    def _has_active_file_handler(self, file_path: Path) -> bool:
        """
        Check if any process has an active file handler on the given file.
        Uses caching to avoid expensive checks on every refresh.
        Returns True if file is open, False if not.
        """
        import time

        # Check cache first
        if self.file_handler_cache is not None:
            cached_result, cached_time = self.file_handler_cache
            if time.time() - cached_time < self.cache_ttl:
                return cached_result

        # Use psutil (auto-installed dependency, cross-platform)
        result = self._check_file_open_psutil(file_path)
        if result is not None:
            self.file_handler_cache = (result, time.time())
            return result

        # psutil failed (should never happen) - assume file is open to be safe
        return True

    def get_scan_status(self) -> str:
        """
        Get the current scan status.
        Returns: "RUNNING", "FINISHED", "INTERRUPTED", or "UNKNOWN"
        """
        status = self.scan_info.get("data", {}).get("status", "UNKNOWN")

        # Only check for active processes if status is RUNNING
        # Skip expensive checks for FINISHED scans
        if status == "RUNNING":
            json_file = self.scan_path / "output.json"
            if json_file.exists():
                # Check if process has file open (uses psutil with caching)
                if not self._has_active_file_handler(json_file):
                    # No process has the file open -> scan is interrupted
                    return "INTERRUPTED"

        return status

    def is_scan_running(self) -> bool:
        """Check if the scan is currently running (not interrupted or finished)"""
        return self.get_scan_status() == "RUNNING"

    def check_for_updates(self) -> bool:
        """Check if output.json has new data and scan is still running"""
        status = self.get_scan_status()

        # Don't check for updates if scan is finished or interrupted
        if status in ["FINISHED", "INTERRUPTED"]:
            return False

        json_file = self.scan_path / "output.json"
        if not json_file.exists():
            return False

        try:
            current_size = json_file.stat().st_size

            # Check if file has grown
            if current_size > self.file_position:
                return True
        except:
            pass

        return False

    def load_new_events(self) -> int:
        """Load only new events that have been added since last read. Returns number of new events."""
        json_file = self.scan_path / "output.json"
        if not json_file.exists():
            return 0

        new_event_count = 0

        try:
            with open(json_file, "r") as f:
                # Seek to last known position
                f.seek(self.file_position)

                for line in f:
                    line = line.strip()
                    if line:
                        try:
                            event = json.loads(line)
                            if event.get("type") == "SCAN":
                                # Always update scan info to keep the LAST SCAN event
                                self.scan_info = event
                            else:
                                self.events.append(event)
                                new_event_count += 1
                        except json.JSONDecodeError:
                            # Skip malformed lines (might be incomplete writes)
                            continue

            # Update file position
            self.file_position = json_file.stat().st_size

        except Exception as e:
            # If there's an error reading incrementally, we'll try again next time
            pass

        return new_event_count

    def load_preset(self):
        """Load preset configuration from preset.yml"""
        preset_file = self.scan_path / "preset.yml"
        if preset_file.exists():
            try:
                with open(preset_file, 'r') as f:
                    self.preset_content = f.read()
            except Exception as e:
                self.preset_content = f"Error loading preset: {e}"
        else:
            self.preset_content = "No preset.yml found in scan directory"

    def get_statistics(self) -> Dict[str, Any]:
        """Calculate statistics from events"""
        event_types = {}
        modules = {}
        scope_distances = {}

        for event in self.events:
            event_type = event.get("type", "UNKNOWN")
            module = event.get("module", "UNKNOWN")
            scope_dist = event.get("scope_distance", 0)

            event_types[event_type] = event_types.get(event_type, 0) + 1
            modules[module] = modules.get(module, 0) + 1
            scope_distances[scope_dist] = scope_distances.get(scope_dist, 0) + 1

        return {
            "total_events": len(self.events),
            "event_types": event_types,
            "modules": modules,
            "scope_distances": scope_distances,
            "scan_name": self.scan_name,
            "started_at": self.scan_info.get("data", {}).get("started_at", "Unknown"),
        }


class StatisticsView(VerticalScroll):
    """Display scan statistics with rich formatting"""

    def __init__(self, scan_data: ScanData, **kwargs):
        super().__init__(**kwargs)
        self.scan_data = scan_data

    def on_mount(self) -> None:
        """Build statistics display on mount"""
        self.build_statistics()

    def build_statistics(self) -> None:
        """Build or rebuild statistics display"""
        stats = self.scan_data.get_statistics()

        # Header section
        header = f"[bold cyan]Scan Statistics[/bold cyan]\n"
        header += f"[dim]Scan:[/dim] [yellow]{stats['scan_name']}[/yellow]\n"
        header += f"[dim]Started:[/dim] {stats['started_at']}\n"
        header += f"[dim]Total Events:[/dim] [bold green]{stats['total_events']:,}[/bold green]\n"
        self.mount(Static(header))

        # Event Types Table
        event_table = RichTable(
            title="ðŸ“Š Event Types Distribution",
            show_header=True,
            header_style="bold magenta",
            border_style="blue",
            title_style="bold white"
        )
        event_table.add_column("Event Type", style="cyan", no_wrap=True)
        event_table.add_column("Count", justify="right", style="green")
        event_table.add_column("Percentage", justify="right", style="yellow")

        total = stats['total_events']
        for event_type, count in sorted(
            stats["event_types"].items(), key=lambda x: x[1], reverse=True
        ):
            percentage = (count / total * 100) if total > 0 else 0
            event_table.add_row(
                event_type,
                f"{count:,}",
                f"{percentage:.1f}%"
            )

        self.mount(Static(event_table))

        # Top Modules Table
        module_table = RichTable(
            title="ðŸ”§ Top 15 Modules",
            show_header=True,
            header_style="bold magenta",
            border_style="green",
            title_style="bold white"
        )
        module_table.add_column("Rank", style="dim", width=6)
        module_table.add_column("Module", style="cyan")
        module_table.add_column("Events", justify="right", style="green")
        module_table.add_column("Percentage", justify="right", style="yellow")

        for idx, (module, count) in enumerate(sorted(
            stats["modules"].items(), key=lambda x: x[1], reverse=True
        )[:15], 1):
            percentage = (count / total * 100) if total > 0 else 0
            rank_style = "bold red" if idx == 1 else "bold yellow" if idx == 2 else "bold white" if idx == 3 else "dim"
            module_table.add_row(
                f"#{idx}",
                module,
                f"{count:,}",
                f"{percentage:.1f}%"
            )

        self.mount(Static(module_table))

        # Scope Distance Table
        scope_table = RichTable(
            title="ðŸŽ¯ Scope Distance Distribution",
            show_header=True,
            header_style="bold magenta",
            border_style="yellow",
            title_style="bold white"
        )
        scope_table.add_column("Distance", style="cyan", justify="center")
        scope_table.add_column("Events", justify="right", style="green")
        scope_table.add_column("Percentage", justify="right", style="yellow")
        scope_table.add_column("Bar", style="blue")

        for scope_dist, count in sorted(stats["scope_distances"].items()):
            percentage = (count / total * 100) if total > 0 else 0
            bar_length = int(percentage / 2)  # Scale to max 50 chars
            bar = "â–ˆ" * bar_length
            scope_table.add_row(
                str(scope_dist),
                f"{count:,}",
                f"{percentage:.1f}%",
                bar
            )

        self.mount(Static(scope_table))

    def refresh_statistics(self) -> None:
        """Clear and rebuild statistics with updated data"""
        # Remove all existing children
        self.remove_children()
        # Rebuild with new data
        self.build_statistics()


class PresetView(Static):
    """Display preset configuration"""

    def __init__(self, scan_data: ScanData, **kwargs):
        super().__init__(**kwargs)
        self.scan_data = scan_data

    def on_mount(self) -> None:
        """Update content when mounted"""
        if self.scan_data.preset_content:
            syntax = Syntax(
                self.scan_data.preset_content,
                "yaml",
                theme="monokai",
                line_numbers=True,
                word_wrap=False
            )
            self.update(syntax)
        else:
            self.update("No preset configuration available")


class VulnerabilitiesTable(DataTable):
    """DataTable for displaying VULNERABILITY events sorted by severity"""

    # Severity order for sorting (higher value = higher severity)
    SEVERITY_ORDER = {
        "CRITICAL": 5,
        "HIGH": 4,
        "MEDIUM": 3,
        "LOW": 2,
        "INFO": 1,
        "UNKNOWN": 0,
    }

    # Limit display to prevent UI performance issues
    MAX_DISPLAY_ROWS = 1000

    def __init__(self, scan_data: ScanData, **kwargs):
        super().__init__(**kwargs)
        self.scan_data = scan_data
        # Only include VULNERABILITY events
        self.vulnerabilities = [
            e for e in scan_data.events
            if e.get("type") == "VULNERABILITY"
        ]
        self.cursor_type = "row"

    def _get_severity(self, vuln: Dict[str, Any]) -> str:
        """Get the severity level of a vulnerability"""
        return vuln.get("data", {}).get("severity", "UNKNOWN")

    def _sort_vulnerabilities_by_severity(self) -> None:
        """Sort vulnerabilities by severity (highest first)"""
        self.vulnerabilities.sort(
            key=lambda v: self.SEVERITY_ORDER.get(self._get_severity(v).upper(), 0),
            reverse=True
        )

    def on_mount(self) -> None:
        """Set up the vulnerabilities table"""
        self.add_columns("Severity", "Host", "Description", "URL", "Module")

        # Sort vulnerabilities by severity before displaying
        self._sort_vulnerabilities_by_severity()

        # Limit to MAX_DISPLAY_ROWS for performance
        display_vulns = self.vulnerabilities[:self.MAX_DISPLAY_ROWS]

        for vuln in display_vulns:
            from rich.text import Text
            data = vuln.get("data", {})
            severity = data.get("severity", "UNKNOWN")
            host = data.get("host", "")
            # Use Text.from_markup() with escape to prevent bracket interpretation
            description = Text(data.get("description", "")[:70], no_wrap=True, overflow="ellipsis")
            url = Text(data.get("url", "")[:40], no_wrap=True, overflow="ellipsis")
            module = vuln.get("module", "")

            self.add_row(severity, host, description, url, module)

    def on_key(self, event) -> None:
        """Handle key events for wraparound navigation"""
        if event.key == "down" or event.key == "j":
            if self.cursor_row == self.row_count - 1:
                self.move_cursor(row=0)
                event.stop()
        elif event.key == "up" or event.key == "k":
            if self.cursor_row == 0:
                self.move_cursor(row=self.row_count - 1)
                event.stop()


class FindingsTable(DataTable):
    """DataTable for displaying FINDING events (no severity filtering)"""

    # Limit display to prevent UI performance issues
    MAX_DISPLAY_ROWS = 1000

    def __init__(self, scan_data: ScanData, **kwargs):
        super().__init__(**kwargs)
        self.scan_data = scan_data
        # Only include FINDING events
        self.findings = [
            e for e in scan_data.events
            if e.get("type") == "FINDING"
        ]
        self.cursor_type = "row"

    def on_mount(self) -> None:
        """Set up the findings table"""
        self.add_columns("Host", "Description", "URL", "Module")

        # Limit to MAX_DISPLAY_ROWS for performance
        display_findings = self.findings[:self.MAX_DISPLAY_ROWS]

        for finding in display_findings:
            from rich.text import Text
            data = finding.get("data", {})
            host = data.get("host", "")
            # Use Text() to treat content as plain text (no markup interpretation)
            description = Text(data.get("description", "")[:70], no_wrap=True, overflow="ellipsis")
            url = Text(data.get("url", "")[:40], no_wrap=True, overflow="ellipsis")
            module = finding.get("module", "")

            self.add_row(host, description, url, module)

    def on_key(self, event) -> None:
        """Handle key events for wraparound navigation"""
        if event.key == "down" or event.key == "j":
            if self.cursor_row == self.row_count - 1:
                self.move_cursor(row=0)
                event.stop()
        elif event.key == "up" or event.key == "k":
            if self.cursor_row == 0:
                self.move_cursor(row=self.row_count - 1)
                event.stop()


class FindingDetailView(VerticalScroll):
    """Display formatted view of selected finding"""

    finding_json = reactive({})

    def __init__(self, **kwargs):
        super().__init__(**kwargs)

    def watch_finding_json(self, finding_json: Dict[str, Any]) -> None:
        """React to finding selection changes"""
        self.update_content(finding_json)

    def update_content(self, finding_json: Dict[str, Any]) -> None:
        """Update the displayed finding details with formatted output"""
        # Remove all existing children
        self.remove_children()

        if not finding_json:
            self.mount(Static("Select a finding to view details"))
            return

        # Extract key information
        event_type = finding_json.get("type", "UNKNOWN")
        data = finding_json.get("data", {})

        # Build plain text content (no Markdown, no special formatting)
        content = f"{event_type}\n\n"

        # Severity (VULNERABILITY only)
        if event_type == "VULNERABILITY":
            severity = data.get("severity", "UNKNOWN")
            content += f"Severity: {severity}\n\n"

        # Host and URL
        host = data.get("host", finding_json.get("host", "N/A"))
        content += f"Host: {host}\n"

        url = data.get("url", "N/A")
        content += f"URL: {url}\n\n"

        # Description (main finding)
        description = data.get("description", "No description available")
        content += f"Description:\n{description}\n\n"

        # Module information
        module = finding_json.get("module", "N/A")
        module_sequence = finding_json.get("module_sequence", "N/A")
        content += f"Module: {module}\n"
        content += f"Module Sequence: {module_sequence}\n\n"

        # Discovery context
        discovery_context = finding_json.get("discovery_context", "")
        if discovery_context:
            content += f"Discovery Context:\n{discovery_context}\n\n"

        # Discovery path
        discovery_path = finding_json.get("discovery_path", [])
        if discovery_path:
            content += f"Discovery Path:\n"
            for i, step in enumerate(discovery_path, 1):
                content += f"{i}. {step}\n"
            content += "\n"

        # Tags
        tags = finding_json.get("tags", [])
        if tags:
            content += f"Tags: {', '.join(str(t) for t in tags)}\n\n"

        # Timestamp
        timestamp = finding_json.get("timestamp", "N/A")
        content += f"Timestamp: {timestamp}\n\n"

        # Additional metadata
        resolved_hosts = finding_json.get("resolved_hosts", [])
        if resolved_hosts:
            content += f"Resolved IPs: {', '.join(str(h) for h in resolved_hosts)}\n"

        port = finding_json.get("port")
        if port:
            content += f"Port: {port}\n"

        # Disable markdown parsing to preserve all special characters
        self.mount(Static(content, markup=False))


class EventTable(DataTable):
    """DataTable for displaying events"""

    def __init__(self, scan_data: ScanData, **kwargs):
        super().__init__(**kwargs)
        self.scan_data = scan_data
        self.filtered_events = scan_data.events
        self.cursor_type = "row"

    def on_mount(self) -> None:
        """Set up the table when mounted"""
        self.add_columns("Type", "Data", "Module", "Scope", "Timestamp")
        self.refresh_table()

    def on_key(self, event) -> None:
        """Handle key events for wraparound navigation"""
        if event.key == "down" or event.key == "j":
            if self.cursor_row == self.row_count - 1:
                self.move_cursor(row=0)
                event.stop()
        elif event.key == "up" or event.key == "k":
            if self.cursor_row == 0:
                self.move_cursor(row=self.row_count - 1)
                event.stop()

    def refresh_table(self, event_type_filter: str = None, scope_distance_filter: int = None):
        """Refresh table with optional filters"""
        self.clear()

        # Start with all events
        filtered = self.scan_data.events

        # Apply type filter
        if event_type_filter and event_type_filter != "All":
            filtered = [e for e in filtered if e.get("type") == event_type_filter]

        # Apply scope distance filter (now accepts integer for max scope distance)
        if scope_distance_filter is not None:
            filtered = [e for e in filtered if e.get("scope_distance", 0) <= scope_distance_filter]

        self.filtered_events = filtered

        for event in self.filtered_events[:1000]:  # Limit to first 1000 for performance
            event_type = event.get("type", "")
            data = str(event.get("data", ""))[:50]  # Truncate long data
            module = event.get("module", "")
            scope = str(event.get("scope_distance", ""))
            timestamp = event.get("timestamp", "")

            if timestamp:
                try:
                    # Try to parse and format timestamp
                    if isinstance(timestamp, str):
                        dt = datetime.fromisoformat(timestamp.replace("Z", "+00:00"))
                        timestamp = dt.strftime("%H:%M:%S")
                except:
                    timestamp = str(timestamp)[:10]

            self.add_row(event_type, data, module, scope, timestamp)


class EventDetailView(VerticalScroll):
    """Display detailed view of selected event"""

    event_json = reactive({})

    def __init__(self, **kwargs):
        super().__init__(**kwargs)

    def watch_event_json(self, event_json: Dict[str, Any]) -> None:
        """React to event selection changes"""
        self.update_content(event_json)

    def update_content(self, event_json: Dict[str, Any]) -> None:
        """Update the displayed event details"""
        # Remove all existing children
        self.remove_children()

        if not event_json:
            self.mount(Static("Select an event to view details"))
            return

        json_str = json.dumps(event_json, indent=2)
        syntax = Syntax(json_str, "json", theme="monokai", line_numbers=True)
        self.mount(Static(syntax))


class DiscoveryTree(Tree):
    """Tree widget showing event discovery hierarchy"""

    # Limit tree nodes to prevent UI performance issues
    # Trees are more expensive to render than tables
    MAX_TREE_NODES = 500

    def __init__(self, scan_data: ScanData, **kwargs):
        super().__init__("Discovery", **kwargs)
        self.scan_data = scan_data
        self.uuid_to_event = {}
        self.uuid_to_node = {}
        self.view_mode = "discovery"  # "discovery" or "topology"
        self.type_filter = None  # Filter by event type
        self.scope_filter = None  # Filter by max scope distance

    def on_mount(self) -> None:
        """Build the tree when mounted"""
        self.build_tree()

    def switch_mode(self, mode: str) -> None:
        """Switch between discovery and topology modes, preserving filters"""
        self.view_mode = mode
        # Preserve current filters when switching modes
        self.clear()
        self.uuid_to_event = {}
        self.uuid_to_node = {}
        self.build_tree()

    def rebuild_tree(self, type_filter: str = None, scope_filter: int = None) -> None:
        """Clear and rebuild the tree with updated filters"""
        self.type_filter = type_filter
        self.scope_filter = scope_filter
        self.clear()
        self.uuid_to_event = {}
        self.uuid_to_node = {}
        self.build_tree()

    def build_tree(self) -> None:
        """Build the tree based on current view mode"""
        if self.view_mode == "discovery":
            self._build_discovery_tree()
        else:
            self._build_topology_tree()

        # Expand root by default
        self.root.expand()

    def _filter_event(self, event: Dict[str, Any]) -> bool:
        """Check if event passes current filters"""
        # Apply type filter
        if self.type_filter and self.type_filter != "All":
            if event.get("type") != self.type_filter:
                return False

        # Apply scope distance filter
        if self.scope_filter is not None:
            if event.get("scope_distance", 0) > self.scope_filter:
                return False

        return True

    def _build_discovery_tree(self) -> None:
        """Build discovery tree based on parent_uuid relationships"""
        uuid_to_children = {}

        # Get SCAN uuid from scan_info
        scan_uuid = self.scan_data.scan_info.get("uuid")

        # Limit events processed for performance
        events_to_process = self.scan_data.events[:self.MAX_TREE_NODES]

        # Index all events by parent (only include events that pass filter)
        for event in events_to_process:
            if not self._filter_event(event):
                continue

            event_uuid = event.get("uuid")
            self.uuid_to_event[event_uuid] = event
            parent_uuid = event.get("parent_uuid")

            if parent_uuid not in uuid_to_children:
                uuid_to_children[parent_uuid] = []
            uuid_to_children[parent_uuid].append(event)

        # Build tree starting from SCAN's children (skip SCAN itself)
        if scan_uuid and scan_uuid in uuid_to_children:
            root_events = uuid_to_children[scan_uuid]
            for event in root_events:
                self._add_event_node(self.root, event, uuid_to_children)

    def _build_topology_tree(self) -> None:
        """Build topology tree based on logical network hierarchy"""
        # Group events by type and host
        ip_ranges = []
        ip_addresses = {}     # keyed by IP
        dns_names = {}        # keyed by DNS name
        hosts = {}            # keyed by host - stores URLs, ports, findings
        http_responses = {}   # keyed by URL
        web_parameters = {}   # keyed by parent URL
        technologies = {}     # keyed by host
        others = []

        # Limit events processed for performance
        events_to_process = self.scan_data.events[:self.MAX_TREE_NODES]

        for event in events_to_process:
            # Skip events that don't pass filter
            if not self._filter_event(event):
                continue
            event_type = event.get("type")
            host = event.get("host", "")

            if event_type == "IP_RANGE":
                ip_ranges.append(event)
            elif event_type == "IP_ADDRESS":
                ip = event.get("data")
                if ip not in ip_addresses:
                    ip_addresses[ip] = event
            elif event_type == "DNS_NAME":
                dns_name = event.get("data", "")
                if dns_name not in dns_names:
                    dns_names[dns_name] = event
            elif event_type == "OPEN_TCP_PORT":
                if host not in hosts:
                    hosts[host] = {"ports": [], "urls": [], "findings": [], "tech": []}
                hosts[host]["ports"].append(event)
            elif event_type in ["URL", "URL_UNVERIFIED"]:
                if host not in hosts:
                    hosts[host] = {"ports": [], "urls": [], "findings": [], "tech": []}
                hosts[host]["urls"].append(event)
            elif event_type in ["VULNERABILITY", "FINDING"]:
                if host not in hosts:
                    hosts[host] = {"ports": [], "urls": [], "findings": [], "tech": []}
                hosts[host]["findings"].append(event)
            elif event_type == "HTTP_RESPONSE":
                # Group HTTP responses under their URL
                parent_url = event.get("parent")
                if parent_url:
                    if parent_url not in http_responses:
                        http_responses[parent_url] = []
                    http_responses[parent_url].append(event)
            elif event_type == "WEB_PARAMETER":
                # Group web parameters under their parent URL
                parent = event.get("parent")
                if parent:
                    if parent not in web_parameters:
                        web_parameters[parent] = []
                    web_parameters[parent].append(event)
            elif event_type == "TECHNOLOGY":
                if host not in hosts:
                    hosts[host] = {"ports": [], "urls": [], "findings": [], "tech": []}
                hosts[host]["tech"].append(event)
            else:
                others.append(event)

        # Build tree structure

        # 1. IP Ranges and IPs
        if ip_ranges:
            for ip_range in ip_ranges:
                range_label = f"IP_RANGE: {ip_range.get('data', '')}"
                range_node = self.root.add(range_label, data=ip_range)
                self.uuid_to_event[ip_range.get('uuid')] = ip_range

                # Add IPs under range that have associated data
                for ip, ip_event in sorted(ip_addresses.items()):
                    if ip in hosts:  # Only show IPs that have ports/URLs/findings
                        ip_node = range_node.add(f"IP_ADDRESS: {ip}", data=ip_event)
                        self._build_host_subtree(ip_node, ip, hosts.get(ip, {}))
                        ip_node.expand()

                range_node.expand()

        # 2. DNS Names with hierarchy
        if dns_names:
            # Build DNS hierarchy (parent domains with subdomains)
            root_domains = {}
            for dns_name, event in dns_names.items():
                parts = dns_name.split(".")
                if len(parts) >= 2:
                    root_domain = ".".join(parts[-2:])  # e.g., "example.com"
                    if root_domain not in root_domains:
                        root_domains[root_domain] = []
                    root_domains[root_domain].append((dns_name, event))

            for root_domain, names in sorted(root_domains.items()):
                # Create root domain node
                root_names = [n for n in names if n[0] == root_domain]
                if root_names:
                    root_event = root_names[0][1]
                    domain_node = self.root.add(f"DNS_NAME: {root_domain}", data=root_event)

                    # Add subdomains
                    subdomains = [n for n in names if n[0] != root_domain]
                    for subdomain, event in sorted(subdomains):
                        sub_node = domain_node.add(f"DNS_NAME: {subdomain}", data=event)

                    domain_node.expand()

        # 3. Hosts (domains/IPs) with their URLs, ports, and findings
        for host in sorted(hosts.keys()):
            # Skip if already added under IP_RANGE
            if host in ip_addresses:
                continue

            host_node = self.root.add(f"Host: {host}")
            self._build_host_subtree(host_node, host, hosts[host])
            host_node.expand()

        # 4. Other events
        if others:
            other_node = self.root.add("Other Events")
            for event in others:
                self._add_simple_node(other_node, event)
            other_node.expand()

    def _build_host_subtree(self, parent_node: TreeNode, host: str, host_data: dict) -> None:
        """Build subtree for a host with ports, URLs, and findings"""
        # Add ports
        for port_event in sorted(host_data.get("ports", []), key=lambda e: e.get("port", 0)):
            self._add_simple_node(parent_node, port_event)

        # Add technologies
        for tech_event in host_data.get("tech", []):
            self._add_simple_node(parent_node, tech_event)

        # Add URLs with their findings
        for url_event in sorted(host_data.get("urls", []), key=lambda e: e.get("data", "")):
            url_node = self._add_simple_node(parent_node, url_event)

            # Check if this URL has findings
            url_data = url_event.get("data", "")
            for finding in host_data.get("findings", []):
                finding_url = finding.get("data", {}).get("url", "")
                if finding_url == url_data:
                    self._add_simple_node(url_node, finding)
                    url_node.expand()

        # Add findings not associated with specific URLs
        for finding in host_data.get("findings", []):
            finding_url = finding.get("data", {}).get("url", "")
            # Only add if not already added under a URL
            if not finding_url or not any(u.get("data") == finding_url for u in host_data.get("urls", [])):
                self._add_simple_node(parent_node, finding)

    def _add_event_node(self, parent_node: TreeNode, event: Dict[str, Any],
                       uuid_to_children: Dict[str, List[Dict[str, Any]]]) -> TreeNode:
        """Recursively add event nodes to the tree (for discovery mode)"""
        event_uuid = event.get("uuid")
        event_type = event.get("type")
        data = event.get("data", "")

        # Format label based on event type
        if event_type == "VULNERABILITY":
            severity = event.get("data", {}).get("severity", "")
            label = f"âš ï¸  {event_type}: {severity} - {str(data)[:60]}"
        elif event_type == "FINDING":
            label = f"ðŸ” {event_type}: {str(data)[:60]}"
        else:
            label = f"{event_type}: {str(data)[:60]}"

        # Add node
        node = parent_node.add(label, data=event)
        self.uuid_to_node[event_uuid] = node

        # Add children recursively
        if event_uuid in uuid_to_children:
            children = uuid_to_children[event_uuid]
            for child in children:
                self._add_event_node(node, child, uuid_to_children)
            # Expand node if it has children
            node.expand()

        return node

    def _add_simple_node(self, parent_node: TreeNode, event: Dict[str, Any]) -> TreeNode:
        """Add a simple node without recursion (for topology mode)"""
        event_uuid = event.get("uuid")
        event_type = event.get("type")
        data = event.get("data", "")

        # Format label based on event type
        if event_type == "VULNERABILITY":
            severity = event.get("data", {}).get("severity", "")
            label = f"âš ï¸  {event_type}: {severity} - {str(data)[:60]}"
        elif event_type == "FINDING":
            label = f"ðŸ” {event_type}: {str(data)[:60]}"
        else:
            label = f"{event_type}: {str(data)[:60]}"

        # Add node
        node = parent_node.add(label, data=event)
        self.uuid_to_event[event_uuid] = event
        self.uuid_to_node[event_uuid] = node

        return node


class TreeDetailView(VerticalScroll):
    """Display detailed view of selected tree node"""

    event_json = reactive({})

    def __init__(self, **kwargs):
        super().__init__(**kwargs)

    def watch_event_json(self, event_json: Dict[str, Any]) -> None:
        """React to event selection changes"""
        self.update_content(event_json)

    def update_content(self, event_json: Dict[str, Any]) -> None:
        """Update the displayed event details"""
        # Remove all existing children
        self.remove_children()

        if not event_json:
            self.mount(Static("Select a node to view details"))
            return

        json_str = json.dumps(event_json, indent=2)
        syntax = Syntax(json_str, "json", theme="monokai", line_numbers=True)
        self.mount(Static(syntax))


class ScanListScreen(Screen):
    """Screen to select a scan from a list"""

    BINDINGS = [
        Binding("q", "quit", "Quit"),
        Binding("escape", "quit", "Quit"),
        Binding("r", "refresh_scans", "Refresh"),
        Binding("a", "archive_selected", "Archive"),
        Binding("d", "delete_selected", "Delete"),
        Binding("tab", "switch_to_archives", "Archives"),
    ]

    def __init__(self, scans_dir: Path, refresh_interval: float = 3.0):
        super().__init__()
        self.scans_dir = scans_dir
        self.refresh_interval = refresh_interval
        self.scans = self.discover_scans(initial_load=True)
        self.refresh_timer = None
        self.scan_statuses = {}  # Track scan status for each scan
        self.scan_event_counts = {}  # Cache event/vuln/finding counts for FINISHED/INTERRUPTED scans: {scan_name: (events, vulns, findings)}
        self.file_handler_cache = {}  # Cache file handler check results: {path: (result, timestamp)}
        self.cache_ttl = 5.0  # Cache results for 5 seconds

    def _check_file_open_psutil(self, file_path: Path) -> bool:
        """
        Check if file is open using psutil (native Python, cross-platform).
        Returns True if open, False if not, None if psutil unavailable.
        """
        try:
            import psutil
            file_path_str = str(file_path.resolve())

            # Iterate through all processes
            for proc in psutil.process_iter(['pid', 'name']):
                try:
                    # Check if process has the file open
                    for open_file in proc.open_files():
                        if open_file.path == file_path_str:
                            return True
                except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                    # Process ended or we don't have permission
                    continue

            return False
        except ImportError:
            # psutil not available
            return None
        except Exception:
            # Other error
            return None


    def _check_active_file_handler(self, file_path: Path) -> bool:
        """
        Check if any process has an active file handler on the given file.
        Uses caching to avoid expensive checks on every refresh.
        Returns True if file is open, False if not.
        """
        import time

        # Check cache first
        cache_key = str(file_path)
        if cache_key in self.file_handler_cache:
            cached_result, cached_time = self.file_handler_cache[cache_key]
            if time.time() - cached_time < self.cache_ttl:
                return cached_result

        # Use psutil (auto-installed dependency, cross-platform)
        result = self._check_file_open_psutil(file_path)
        if result is not None:
            self.file_handler_cache[cache_key] = (result, time.time())
            return result

        # psutil failed (should never happen) - assume file is open to be safe
        return True

    def _get_last_scan_event(self, file_path: Path, thorough: bool = False) -> dict:
        """
        Get the MOST RECENT SCAN event from output.json.

        Note: The same scan directory can be reused multiple times, so the file may contain
        multiple SCAN events with different IDs. We need to find the chronologically last one.

        Args:
            thorough: If True, read entire file to find all SCAN events (100% reliable).
                     If False, use optimized approach (read first 200KB and last 50KB).
                     Use thorough=True for FINISHED/INTERRUPTED scans (checked only once).
                     Use thorough=False for RUNNING scans (checked repeatedly).
        """
        scan_events = []

        try:
            if thorough:
                # Read entire file to find ALL SCAN events (100% reliable)
                # This is acceptable for FINISHED/INTERRUPTED scans since we only do it once
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    for line in f:
                        line = line.strip()
                        if not line:
                            continue
                        try:
                            event = json.loads(line)
                            if event.get("type") == "SCAN":
                                scan_events.append(event)
                        except:
                            continue
            else:
                # Optimized approach: read from both ends (for RUNNING scans checked repeatedly)
                with open(file_path, 'rb') as f:
                    f.seek(0, 2)
                    file_size = f.tell()

                    # Read from END (most recent events, including FINISHED scans)
                    read_size = min(50000, file_size)
                    f.seek(max(0, file_size - read_size))
                    tail = f.read().decode('utf-8', errors='ignore')

                    for line in tail.split('\n'):
                        line = line.strip()
                        if not line:
                            continue
                        try:
                            event = json.loads(line)
                            if event.get("type") == "SCAN":
                                scan_events.append(event)
                        except:
                            continue

                    # Read from BEGINNING (for old scan runs and RUNNING scans)
                    f.seek(0)
                    head = f.read(min(200000, file_size))
                    head_text = head.decode('utf-8', errors='ignore')

                    for line in head_text.split('\n'):
                        line = line.strip()
                        if not line:
                            continue
                        try:
                            event = json.loads(line)
                            if event.get("type") == "SCAN":
                                # Check if we already have this one (avoid duplicates)
                                event_id = event.get("id")
                                if not any(e.get("id") == event_id and e.get("data", {}).get("status") == event.get("data", {}).get("status") for e in scan_events):
                                    scan_events.append(event)
                        except:
                            continue

            # Return the SCAN event with the most recent timestamp
            if scan_events:
                # Sort by timestamp (most recent last)
                scan_events.sort(key=lambda e: e.get("timestamp", ""), reverse=False)
                return scan_events[-1]  # Return most recent

        except:
            pass

        return None

    def _estimate_event_counts(self, file_path: Path, thorough: bool = False) -> tuple:
        """
        Get event, vulnerability, and finding counts from output.json.

        Args:
            thorough: If True, count exactly by reading entire file (100% accurate).
                     If False, use estimation for large files (fast but approximate).
                     Use thorough=True for initial load (only once).
                     Use thorough=False for periodic refresh (repeatedly).

        Returns:
            Tuple of (event_count, vuln_count, finding_count)
        """
        try:
            stat = file_path.stat()
            file_size = stat.st_size

            # If thorough mode or small file, count exactly
            if thorough or file_size < 1_000_000:
                event_count = 0
                vuln_count = 0
                finding_count = 0
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    for line in f:
                        try:
                            event = json.loads(line.strip())
                            event_type = event.get("type", "")
                            if event_type != "SCAN":
                                event_count += 1
                            if event_type == "FINDING":
                                finding_count += 1
                            elif event_type == "VULNERABILITY":
                                vuln_count += 1
                        except:
                            continue
                return (event_count, vuln_count, finding_count)

            # For large files in non-thorough mode, estimate based on line count
            # Average BBOT event line is ~200-300 bytes
            estimated_lines = file_size // 250

            # Sample last 100 lines to estimate vulnerability/finding ratio
            # (Findings typically appear later in scans, so sample from end)
            vuln_count = 0
            finding_count = 0
            sample_size = 0
            with open(file_path, 'rb') as f:
                # Read last 50KB
                f.seek(0, 2)
                file_size = f.tell()
                read_size = min(50000, file_size)
                f.seek(max(0, file_size - read_size))
                tail = f.read().decode('utf-8', errors='ignore')

                lines = tail.split('\n')
                # Sample last 100 complete lines
                for line in lines[-100:]:
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        event = json.loads(line)
                        event_type = event.get("type", "")
                        if event_type != "SCAN":
                            sample_size += 1
                        if event_type == "FINDING":
                            finding_count += 1
                        elif event_type == "VULNERABILITY":
                            vuln_count += 1
                    except:
                        continue

            # Extrapolate vulnerability and finding counts
            if sample_size > 0:
                vuln_ratio = vuln_count / sample_size
                finding_ratio = finding_count / sample_size
                estimated_vulns = int(estimated_lines * vuln_ratio)
                estimated_findings = int(estimated_lines * finding_ratio)
            else:
                estimated_vulns = 0
                estimated_findings = 0

            return (estimated_lines, estimated_vulns, estimated_findings)

        except:
            return (0, 0, 0)

    def discover_scans(self, initial_load: bool = False) -> List[Dict[str, Any]]:
        """
        Discover all scan directories (optimized for large scans)

        Args:
            initial_load: If True, defer RUNNING status checks (show as UNKNOWN)
                         If False, perform full status checks (for refreshes)
        """
        scans = []

        for scan_dir in sorted(self.scans_dir.iterdir()):
            if not scan_dir.is_dir() or scan_dir.name.startswith('.'):
                continue

            output_json = scan_dir / "output.json"
            if not output_json.exists():
                continue

            # Get scan metadata
            modified_time = "Unknown"
            scan_status = "UNKNOWN"
            is_running = False

            try:
                # Get SCAN event
                # On initial load: use thorough mode (read entire file) for 100% reliability
                # On refresh: use optimized mode (read from both ends) for speed
                scan_event = self._get_last_scan_event(output_json, thorough=initial_load)

                # Extract scan status from the last SCAN event
                if scan_event:
                    scan_status = scan_event.get("data", {}).get("status", "UNKNOWN")

                # Get event counts
                # Strategy: Cache ALL counts on initial load (thorough counting)
                # On refresh: use cached values for all scans, only recalculate for RUNNING scans
                scan_name = scan_dir.name

                if initial_load:
                    # Initial load: always count thoroughly and cache
                    event_count, vuln_count, finding_count = self._estimate_event_counts(output_json, thorough=True)
                    self.scan_event_counts[scan_name] = (event_count, vuln_count, finding_count)
                else:
                    # Refresh: use cached counts for non-RUNNING scans, recalculate for RUNNING
                    current_tracked_status = self.scan_statuses.get(scan_name, "UNKNOWN")
                    if current_tracked_status == "RUNNING":
                        # Recalculate for RUNNING scans with exact counting (thorough mode)
                        # Only 1-2 RUNNING scans max, so CPU impact is minimal
                        event_count, vuln_count, finding_count = self._estimate_event_counts(output_json, thorough=True)
                    elif scan_name in self.scan_event_counts:
                        # Use cached counts for FINISHED/INTERRUPTED/UNKNOWN scans
                        event_count, vuln_count, finding_count = self.scan_event_counts[scan_name]
                    else:
                        # Fallback: count thoroughly if no cache available
                        event_count, vuln_count, finding_count = self._estimate_event_counts(output_json, thorough=True)
                        self.scan_event_counts[scan_name] = (event_count, vuln_count, finding_count)

                # Only check for active processes if status is RUNNING
                # Skip expensive checks for FINISHED scans
                if scan_event:
                    if scan_status == "RUNNING":
                        if initial_load:
                            # On initial load: defer status check to avoid blocking startup
                            # Show as UNKNOWN, will be updated in 0.5s by timer
                            scan_status = "UNKNOWN"
                            is_running = False
                        else:
                            # On refresh: perform full status check using psutil
                            if not self._check_active_file_handler(output_json):
                                scan_status = "INTERRUPTED"
                            is_running = scan_status == "RUNNING"
                    else:
                        # FINISHED scans
                        is_running = False

                # Get last modified time for display
                stat = output_json.stat()
                modified_time = datetime.fromtimestamp(stat.st_mtime).strftime("%Y-%m-%d %H:%M")

                # Track status for change detection
                self.scan_statuses[scan_dir.name] = scan_status

            except Exception:
                pass

            scans.append({
                "name": scan_dir.name,
                "path": scan_dir,
                "event_count": event_count,
                "vuln_count": vuln_count,
                "finding_count": finding_count,
                "modified": modified_time,
                "status": scan_status,
                "is_running": is_running,
            })

        return scans

    def compose(self) -> ComposeResult:
        """Create the scan list UI"""
        yield Header()

        # Calculate totals
        total_vulns = sum(scan["vuln_count"] for scan in self.scans)
        total_findings = sum(scan["finding_count"] for scan in self.scans)

        issues_text = ""
        if total_vulns > 0 or total_findings > 0:
            issues_text = f" ({total_vulns} vulns, {total_findings} findings)"

        with Vertical():
            yield Static(
                f"# Select a Scan\n\nFound {len(self.scans)} scans{issues_text} in {self.scans_dir}\n\nPress Tab to view archives\n",
                id="header"
            )
            yield DataTable(id="scan-table")

        yield Footer()

    def on_mount(self) -> None:
        """Set up the scan table and start auto-refresh"""
        table = self.query_one("#scan-table", DataTable)
        table.cursor_type = "row"
        table.add_columns("Scan Name", "Status", "Events", "Vulns", "Findings", "Last Modified")

        self.refresh_table()

        # Start auto-refresh timer
        self.refresh_timer = self.set_interval(self.refresh_interval, self.check_for_scan_updates)

        # Trigger immediate status check for UNKNOWN scans (those with RUNNING status at startup)
        # This updates them quickly without blocking startup
        self.set_timer(0.5, self.check_for_scan_updates)

    def on_unmount(self) -> None:
        """Clean up timer when screen is removed"""
        if self.refresh_timer:
            self.refresh_timer.stop()

    def on_screen_resume(self) -> None:
        """Called when returning to this screen from another screen"""
        # Refresh the scan list when returning from archives
        self.scans = self.discover_scans(initial_load=False)
        self.refresh_table()

    def refresh_table(self) -> None:
        """Refresh the scan table with current data"""
        table = self.query_one("#scan-table", DataTable)
        old_cursor = table.cursor_row

        # Clear and rebuild table
        table.clear()

        for scan in self.scans:
            scan_name = scan["name"]

            # Format status with colors and indicators
            status = scan.get("status", "UNKNOWN")
            if status == "RUNNING":
                status_str = "[bold green]â— RUNNING[/bold green]"
            elif status == "FINISHED":
                status_str = "[bold blue]âœ“ FINISHED[/bold blue]"
            elif status == "INTERRUPTED":
                status_str = "[bold yellow]âš  INTERRUPTED[/bold yellow]"
            elif status == "UNKNOWN":
                status_str = "[dim italic]â—‹ CHECKING...[/dim italic]"
            else:
                status_str = f"[dim]{status}[/dim]"

            # Format vulnerability count with highlighting if > 0
            vulns_str = str(scan["vuln_count"])
            if scan["vuln_count"] > 0:
                vulns_str = f"[red]âš  {vulns_str}[/red]"

            # Format findings count with highlighting if > 0
            findings_str = str(scan["finding_count"])
            if scan["finding_count"] > 0:
                findings_str = f"[yellow]âš  {findings_str}[/yellow]"

            table.add_row(
                scan_name,
                status_str,
                str(scan["event_count"]),
                vulns_str,
                findings_str,
                scan["modified"],
            )

        # Restore cursor position if possible
        if old_cursor < table.row_count:
            table.move_cursor(row=old_cursor)

    def check_for_scan_updates(self) -> None:
        """Check if any scans have status changes, new scans added, or RUNNING scans with new events"""
        has_changes = False
        has_running_scans = False

        # Check for new scans or status changes
        # Only check RUNNING scans for status changes (optimization)
        for scan_dir in self.scans_dir.iterdir():
            if not scan_dir.is_dir() or scan_dir.name.startswith('.'):
                continue

            output_json = scan_dir / "output.json"
            if not output_json.exists():
                continue

            scan_name = scan_dir.name

            # Check if this is a new scan
            if scan_name not in self.scan_statuses:
                has_changes = True
                break

            # Skip checking scans that are already FINISHED or INTERRUPTED
            # They won't change status (optimization)
            current_tracked_status = self.scan_statuses.get(scan_name, "UNKNOWN")
            if current_tracked_status in ["FINISHED", "INTERRUPTED"]:
                continue

            # Track if we have any RUNNING scans (they need periodic refresh for event counts)
            if current_tracked_status == "RUNNING":
                has_running_scans = True

            # Only check RUNNING scans for status changes
            try:
                # Use optimized mode (read from both ends) since this is called repeatedly
                scan_event = self._get_last_scan_event(output_json, thorough=False)

                if scan_event:
                    current_status = scan_event.get("data", {}).get("status", "UNKNOWN")

                    # Only check for active processes if status is RUNNING
                    # Skip expensive checks for FINISHED scans
                    if current_status == "RUNNING":
                        # Check if process has file open using psutil
                        if not self._check_active_file_handler(output_json):
                            current_status = "INTERRUPTED"

                    if current_status != self.scan_statuses.get(scan_name, ""):
                        has_changes = True
                        break
            except:
                pass

        # If changes detected or RUNNING scans exist, refresh the scan list
        # RUNNING scans need periodic refresh to update event/finding counts
        if has_changes or has_running_scans:
            self.scans = self.discover_scans(initial_load=False)
            self.refresh_table()

    def action_refresh_scans(self) -> None:
        """Manually refresh the scan list"""
        old_count = len(self.scans)
        old_statuses = self.scan_statuses.copy()
        self.scans = self.discover_scans(initial_load=False)
        new_count = len(self.scans)
        self.refresh_table()

        if new_count > old_count:
            self.notify(f"Found {new_count - old_count} new scan(s)", timeout=2)
        elif has_changes := any(
            s["status"] != old_statuses.get(s["name"], "")
            for s in self.scans
        ):
            self.notify("Scan list refreshed", timeout=2)
        else:
            self.notify("No changes detected", timeout=2)

    def action_archive_selected(self) -> None:
        """Archive the selected scan with confirmation"""
        table = self.query_one("#scan-table", DataTable)

        if table.row_count == 0:
            self.notify("No scans to archive", severity="warning", timeout=2)
            return

        if table.cursor_row < len(self.scans):
            selected_scan = self.scans[table.cursor_row]
            scan_name = selected_scan["name"]
            scan_status = selected_scan["status"]

            # Don't allow archiving of RUNNING scans
            if scan_status == "RUNNING":
                self.notify("Cannot archive a running scan", severity="warning", timeout=3)
                return

            # Show confirmation dialog
            self.app.push_screen(
                ConfirmDialog(
                    f"Archive scan '{scan_name}'?\n\nThis will compress the folder to a .zip file and remove the original.",
                    lambda confirmed: self._handle_archive_confirmation(confirmed, selected_scan)
                )
            )

    def _handle_archive_confirmation(self, confirmed: bool, scan: Dict[str, Any]) -> None:
        """Handle the archive confirmation response"""
        if not confirmed:
            self.notify("Archive cancelled", timeout=2)
            return

        # Perform archive operation
        scan_path = scan["path"]
        scan_name = scan["name"]

        success, message = create_archive(scan_path)

        if success:
            self.notify(message, timeout=3)
            # Refresh the scan list
            self.scans = self.discover_scans(initial_load=False)
            self.refresh_table()
        else:
            self.notify(message, severity="error", timeout=5)

    def action_delete_selected(self) -> None:
        """Delete the selected scan with confirmation"""
        table = self.query_one("#scan-table", DataTable)

        if table.row_count == 0:
            self.notify("No scans to delete", severity="warning", timeout=2)
            return

        if table.cursor_row < len(self.scans):
            selected_scan = self.scans[table.cursor_row]
            scan_name = selected_scan["name"]
            scan_status = selected_scan["status"]

            # Don't allow deleting RUNNING scans
            if scan_status == "RUNNING":
                self.notify("Cannot delete a running scan", severity="warning", timeout=3)
                return

            # Show confirmation dialog with warning
            self.app.push_screen(
                ConfirmDialog(
                    f"âš ï¸  DELETE scan '{scan_name}'?\n\nThis action is PERMANENT and cannot be undone!\nAll scan data will be lost.",
                    lambda confirmed: self._handle_delete_confirmation(confirmed, selected_scan)
                )
            )

    def _handle_delete_confirmation(self, confirmed: bool, scan: Dict[str, Any]) -> None:
        """Handle the delete confirmation response"""
        if not confirmed:
            self.notify("Delete cancelled", timeout=2)
            return

        # Perform delete operation
        scan_path = scan["path"]
        scan_name = scan["name"]

        try:
            shutil.rmtree(scan_path)
            self.notify(f"Deleted scan '{scan_name}'", timeout=3)
            # Refresh the scan list
            self.scans = self.discover_scans(initial_load=False)
            self.refresh_table()
        except Exception as e:
            self.notify(f"Failed to delete scan: {str(e)}", severity="error", timeout=5)

    def on_key(self, event) -> None:
        """Handle key events for wraparound navigation in scan list"""
        table = self.query_one("#scan-table", DataTable)
        if event.key == "down" or event.key == "j":
            if table.cursor_row == table.row_count - 1:
                table.move_cursor(row=0)
                event.stop()
        elif event.key == "up" or event.key == "k":
            if table.cursor_row == 0:
                table.move_cursor(row=table.row_count - 1)
                event.stop()

    def action_switch_to_archives(self) -> None:
        """Switch to the archives screen"""
        self.app.push_screen(ArchivesListScreen(self.scans_dir))

    def on_data_table_row_selected(self, event: DataTable.RowSelected) -> None:
        """Handle scan selection"""
        if event.cursor_row < len(self.scans):
            selected_scan = self.scans[event.cursor_row]
            self.app.push_screen(ScanViewerScreen(selected_scan["path"]))


class ArchivesListScreen(Screen):
    """Screen to view and manage archived scans"""

    BINDINGS = [
        Binding("q", "quit_archives", "Back to Scans"),
        Binding("escape", "quit_archives", "Back to Scans"),
        Binding("tab", "quit_archives", "Back to Scans"),
        Binding("r", "refresh_archives", "Refresh"),
        Binding("u", "unarchive_selected", "Unarchive"),
        Binding("d", "delete_selected", "Delete"),
    ]

    def __init__(self, scans_dir: Path):
        super().__init__()
        self.scans_dir = scans_dir
        self.archives = self.discover_archives()

    def discover_archives(self) -> List[Dict[str, Any]]:
        """Discover all ZIP archives in the scans directory"""
        archives = []

        for archive_path in sorted(self.scans_dir.iterdir()):
            # Only process .zip files
            if not archive_path.is_file() or not archive_path.name.endswith('.zip'):
                continue

            # Skip hidden files
            if archive_path.name.startswith('.'):
                continue

            # Get archive statistics
            stats = get_archive_stats(archive_path)
            if not stats:
                continue

            # Format size for display
            size_mb = stats['size'] / (1024 * 1024)
            if size_mb < 1:
                size_str = f"{stats['size'] / 1024:.1f} KB"
            else:
                size_str = f"{size_mb:.1f} MB"

            archives.append({
                "name": archive_path.name[:-4],  # Remove .zip extension
                "path": archive_path,
                "size": size_str,
                "date": stats['date'],
                "event_count": stats['event_count'],
                "vuln_count": stats['vuln_count'],
                "finding_count": stats['finding_count'],
            })

        return archives

    def compose(self) -> ComposeResult:
        """Create the archives list UI"""
        yield Header()

        # Calculate totals
        total_vulns = sum(archive["vuln_count"] for archive in self.archives)
        total_findings = sum(archive["finding_count"] for archive in self.archives)

        issues_text = ""
        if total_vulns > 0 or total_findings > 0:
            issues_text = f" ({total_vulns} vulns, {total_findings} findings)"

        with Vertical():
            yield Static(
                f"# Archived Scans\n\nFound {len(self.archives)} archived scans{issues_text} in {self.scans_dir}\n\nPress 'u' to unarchive, Tab or 'q' to go back\n",
                id="archive-header"
            )
            yield DataTable(id="archive-table")

        yield Footer()

    def on_mount(self) -> None:
        """Set up the archive table"""
        table = self.query_one("#archive-table", DataTable)
        table.cursor_type = "row"
        table.add_columns("Archive Name", "Size", "Events", "Vulns", "Findings", "Date Archived")

        self.refresh_table()

    def refresh_table(self) -> None:
        """Refresh the archive table with current data"""
        table = self.query_one("#archive-table", DataTable)
        old_cursor = table.cursor_row

        # Clear and rebuild table
        table.clear()

        for archive in self.archives:
            archive_name = archive["name"]

            # Format vulnerability count with highlighting if > 0
            vulns_str = str(archive["vuln_count"])
            if archive["vuln_count"] > 0:
                vulns_str = f"[red]âš  {vulns_str}[/red]"

            # Format findings count with highlighting if > 0
            findings_str = str(archive["finding_count"])
            if archive["finding_count"] > 0:
                findings_str = f"[yellow]âš  {findings_str}[/yellow]"

            table.add_row(
                archive_name,
                archive["size"],
                str(archive["event_count"]),
                vulns_str,
                findings_str,
                archive["date"],
            )

        # Restore cursor position if possible
        if old_cursor < table.row_count:
            table.move_cursor(row=old_cursor)

    def action_refresh_archives(self) -> None:
        """Manually refresh the archive list"""
        old_count = len(self.archives)
        self.archives = self.discover_archives()
        new_count = len(self.archives)
        self.refresh_table()

        if new_count > old_count:
            self.notify(f"Found {new_count - old_count} new archive(s)", timeout=2)
        elif new_count < old_count:
            self.notify(f"Removed {old_count - new_count} archive(s)", timeout=2)
        else:
            self.notify("No changes detected", timeout=2)

    def action_unarchive_selected(self) -> None:
        """Unarchive the selected archive with confirmation"""
        table = self.query_one("#archive-table", DataTable)

        if table.row_count == 0:
            self.notify("No archives to unarchive", severity="warning", timeout=2)
            return

        if table.cursor_row < len(self.archives):
            selected_archive = self.archives[table.cursor_row]
            archive_name = selected_archive["name"]

            # Show confirmation dialog
            self.app.push_screen(
                ConfirmDialog(
                    f"Restore archive '{archive_name}.zip'?\n\nThis will extract the scan and remove the archive file.",
                    lambda confirmed: self._handle_unarchive_confirmation(confirmed, selected_archive)
                )
            )

    def _handle_unarchive_confirmation(self, confirmed: bool, archive: Dict[str, Any]) -> None:
        """Handle the unarchive confirmation response"""
        if not confirmed:
            self.notify("Unarchive cancelled", timeout=2)
            return

        # Perform unarchive operation
        archive_path = archive["path"]
        archive_name = archive["name"]

        success, message = extract_archive(archive_path)

        if success:
            self.notify(message, timeout=3)
            # Refresh the archive list
            self.archives = self.discover_archives()
            self.refresh_table()
        else:
            self.notify(message, severity="error", timeout=5)

    def action_delete_selected(self) -> None:
        """Delete the selected archive with confirmation"""
        table = self.query_one("#archive-table", DataTable)

        if table.row_count == 0:
            self.notify("No archives to delete", severity="warning", timeout=2)
            return

        if table.cursor_row < len(self.archives):
            selected_archive = self.archives[table.cursor_row]
            archive_name = selected_archive["name"]

            # Show confirmation dialog with warning
            self.app.push_screen(
                ConfirmDialog(
                    f"âš ï¸  DELETE archive '{archive_name}.zip'?\n\nThis action is PERMANENT and cannot be undone!\nThe archived scan data will be lost.",
                    lambda confirmed: self._handle_delete_archive_confirmation(confirmed, selected_archive)
                )
            )

    def _handle_delete_archive_confirmation(self, confirmed: bool, archive: Dict[str, Any]) -> None:
        """Handle the delete archive confirmation response"""
        if not confirmed:
            self.notify("Delete cancelled", timeout=2)
            return

        # Perform delete operation
        archive_path = archive["path"]
        archive_name = archive["name"]

        try:
            archive_path.unlink()
            self.notify(f"Deleted archive '{archive_name}.zip'", timeout=3)
            # Refresh the archive list
            self.archives = self.discover_archives()
            self.refresh_table()
        except Exception as e:
            self.notify(f"Failed to delete archive: {str(e)}", severity="error", timeout=5)

    def action_quit_archives(self) -> None:
        """Return to scan list"""
        self.app.pop_screen()

    def on_key(self, event) -> None:
        """Handle key events for wraparound navigation in archive list"""
        table = self.query_one("#archive-table", DataTable)
        if event.key == "down" or event.key == "j":
            if table.cursor_row == table.row_count - 1:
                table.move_cursor(row=0)
                event.stop()
        elif event.key == "up" or event.key == "k":
            if table.cursor_row == 0:
                table.move_cursor(row=table.row_count - 1)
                event.stop()


class ConfirmDialog(Screen):
    """Modal dialog for confirmation"""

    def __init__(self, message: str, callback):
        super().__init__()
        self.message = message
        self.callback = callback

    def compose(self) -> ComposeResult:
        with Vertical(id="dialog"):
            yield Static(self.message, id="dialog-message")
            with Horizontal(id="dialog-buttons"):
                yield Button("Cancel", variant="default", id="cancel-button")
                yield Button("Confirm", variant="primary", id="confirm-button")

    def on_mount(self) -> None:
        """Focus confirm button on mount"""
        self.query_one("#confirm-button", Button).focus()

    def on_button_pressed(self, event: Button.Pressed) -> None:
        """Handle button press"""
        confirmed = event.button.id == "confirm-button"
        self.app.pop_screen()
        self.callback(confirmed)

    def on_key(self, event) -> None:
        """Handle escape key"""
        if event.key == "escape":
            self.app.pop_screen()
            self.callback(False)
            event.stop()


class ScanViewerScreen(Screen):
    """Screen to view a single scan"""

    BINDINGS = [
        Binding("q", "quit_viewer", "Back to List"),
        Binding("escape", "quit_viewer", "Back to List"),
        Binding("f", "focus_filter", "Filter"),
        Binding("left", "adjust_split_left", "Split â†"),
        Binding("right", "adjust_split_right", "Split â†’"),
        Binding("r", "refresh_scan", "Refresh"),
    ]

    split_ratio = reactive(60)  # Default 60% for main panel
    scan_status = reactive("UNKNOWN")  # Track current scan status
    total_events = reactive(0)  # Track total event count for updates

    def __init__(self, scan_path: Path, refresh_interval: float = 2.0):
        super().__init__()
        self.scan_data = ScanData(scan_path)
        self.refresh_interval = refresh_interval
        self.current_type_filter = "All"
        self.current_scope_filter = None  # None means "all"
        self.tree_type_filter = "All"
        self.tree_scope_filter = None  # None means "all"
        self.refresh_timer = None

    def compose(self) -> ComposeResult:
        """Create the scan viewer UI"""
        yield Header()

        # Add live status indicator
        yield Static("", id="live-status")

        # Get unique event types for filter
        event_types = ["All"] + sorted(
            list(set(e.get("type", "") for e in self.scan_data.events))
        )

        # Count vulnerabilities and findings for the tab labels
        vuln_count = len([
            e for e in self.scan_data.events
            if e.get("type") == "VULNERABILITY"
        ])
        finding_count = len([
            e for e in self.scan_data.events
            if e.get("type") == "FINDING"
        ])
        vulns_label = f"Vulnerabilities ({vuln_count})" if vuln_count > 0 else "Vulnerabilities"
        findings_label = f"Findings ({finding_count})" if finding_count > 0 else "Findings"

        with TabbedContent(initial="vulnerabilities"):
            with TabPane(vulns_label, id="vulnerabilities"):
                with Horizontal(id="vulnerabilities-pane"):
                    with Vertical(id="vulnerabilities-container"):
                        yield VulnerabilitiesTable(self.scan_data, id="vulnerabilities-table")

                    with Vertical(id="vulnerability-detail-container"):
                        yield FindingDetailView(id="vulnerability-detail")

            with TabPane(findings_label, id="findings"):
                with Horizontal(id="findings-pane"):
                    with Vertical(id="findings-container"):
                        yield FindingsTable(self.scan_data, id="findings-table")

                    with Vertical(id="finding-detail-container"):
                        yield FindingDetailView(id="finding-detail")

            with TabPane("Events", id="events"):
                with Horizontal(id="events-pane"):
                    with Vertical(id="main-container"):
                        with Horizontal(id="filter-container"):
                            with Vertical(id="event-type-col"):
                                yield Label("Type:")
                                yield Select(
                                    [(t, t) for t in event_types],
                                    value="All",
                                    allow_blank=False,
                                    id="event-type-filter",
                                )
                            with Vertical(id="event-scope-col"):
                                yield Label("Scope:")
                                yield Input(placeholder="all", id="scope-distance-input")
                            with Vertical(id="event-search-col"):
                                yield Label("Search (data, tags, module, host):")
                                yield Input(placeholder="space separates terms...", id="search-input")
                        yield EventTable(self.scan_data, id="event-table")

                    with Vertical(id="detail-container"):
                        yield EventDetailView(id="event-detail")

            with TabPane("Tree", id="tree-tab"):
                with Horizontal(id="tree-pane"):
                    with Vertical(id="tree-container"):
                        with Horizontal(id="tree-filter-container"):
                            with Vertical(id="tree-mode-col"):
                                yield Label("View mode:")
                                yield Select(
                                    [("Discovery", "discovery"), ("Topology", "topology")],
                                    value="discovery",
                                    allow_blank=False,
                                    id="tree-mode-select",
                                )
                            with Vertical(id="tree-type-col"):
                                yield Label("Type:")
                                yield Select(
                                    [(t, t) for t in event_types],
                                    value="All",
                                    allow_blank=False,
                                    id="tree-type-filter",
                                )
                            with Vertical(id="tree-scope-col"):
                                yield Label("Scope:")
                                yield Input(placeholder="all", id="tree-scope-input")
                        yield DiscoveryTree(self.scan_data, id="discovery-tree")

                    with Vertical(id="tree-detail-container"):
                        yield TreeDetailView(id="tree-detail")

            with TabPane("Statistics", id="stats-tab"):
                yield StatisticsView(self.scan_data)

            with TabPane("Scan Preset", id="config-tab"):
                # Create syntax highlighted content directly
                if self.scan_data.preset_content:
                    syntax = Syntax(
                        self.scan_data.preset_content,
                        "yaml",
                        theme="monokai",
                        line_numbers=True,
                        word_wrap=False
                    )
                    yield VerticalScroll(Static(syntax))
                else:
                    yield Static("No preset configuration available")

        yield Footer()

    def on_mount(self) -> None:
        """Set up periodic refresh check"""
        self.total_events = len(self.scan_data.events)
        self.scan_status = self.scan_data.get_scan_status()
        # Update initial status
        self.update_status_display()

        # Only start refresh timer for RUNNING scans
        # FINISHED and INTERRUPTED scans don't need periodic checks
        if self.scan_status == "RUNNING":
            self.refresh_timer = self.set_interval(self.refresh_interval, self.check_for_updates)

    def watch_scan_status(self, scan_status: str) -> None:
        """React to scan status changes"""
        self.update_status_display()

        # Stop refresh timer for FINISHED and INTERRUPTED scans to save CPU
        if scan_status in ["FINISHED", "INTERRUPTED"]:
            if self.refresh_timer:
                self.refresh_timer.stop()
                self.refresh_timer = None
        # Restart timer if scan becomes RUNNING again (unlikely but possible)
        elif scan_status == "RUNNING":
            if not self.refresh_timer:
                self.refresh_timer = self.set_interval(self.refresh_interval, self.check_for_updates)

    def watch_total_events(self, total_events: int) -> None:
        """React to event count changes"""
        self.update_status_display()

    def update_status_display(self) -> None:
        """Update the status display indicator"""
        try:
            status_widget = self.query_one("#live-status", Static)
            if self.scan_status == "RUNNING":
                status_widget.update(
                    f"[bold green]â— RUNNING[/bold green] - {self.total_events:,} events (updating...)"
                )
            elif self.scan_status == "FINISHED":
                status_widget.update(
                    f"[bold blue]âœ“ FINISHED[/bold blue] - {self.total_events:,} events"
                )
            elif self.scan_status == "INTERRUPTED":
                status_widget.update(
                    f"[bold yellow]âš  INTERRUPTED[/bold yellow] - {self.total_events:,} events"
                )
            else:
                status_widget.update(
                    f"[dim]â—‹ {self.scan_status}[/dim] - {self.total_events:,} events"
                )
        except:
            pass

    def on_unmount(self) -> None:
        """Clean up timer when screen is removed"""
        if self.refresh_timer:
            self.refresh_timer.stop()

    def check_for_updates(self) -> None:
        """Periodically check for new data and refresh UI if needed"""
        if self.scan_data.check_for_updates():
            new_event_count = self.scan_data.load_new_events()
            if new_event_count > 0:
                self.total_events = len(self.scan_data.events)
                self.scan_status = self.scan_data.get_scan_status()
                self.refresh_ui_components()

        # Always update status in case it changed
        new_status = self.scan_data.get_scan_status()
        if new_status != self.scan_status:
            self.scan_status = new_status


    def refresh_ui_components(self) -> None:
        """Refresh all UI components with new data"""
        # Refresh vulnerabilities table
        try:
            vulns_table = self.query_one("#vulnerabilities-table", VulnerabilitiesTable)
            old_cursor = vulns_table.cursor_row
            vulns_table.vulnerabilities = [
                e for e in self.scan_data.events
                if e.get("type") == "VULNERABILITY"
            ]
            # Sort vulnerabilities by severity
            vulns_table._sort_vulnerabilities_by_severity()
            vulns_table.clear()

            # Limit to MAX_DISPLAY_ROWS for performance
            display_vulns = vulns_table.vulnerabilities[:vulns_table.MAX_DISPLAY_ROWS]

            for vuln in display_vulns:
                from rich.text import Text
                data = vuln.get("data", {})
                severity = data.get("severity", "UNKNOWN")
                host = data.get("host", "")
                # Use Text() to treat content as plain text (no markup interpretation)
                description = Text(data.get("description", "")[:70], no_wrap=True, overflow="ellipsis")
                url = Text(data.get("url", "")[:40], no_wrap=True, overflow="ellipsis")
                module = vuln.get("module", "")
                vulns_table.add_row(severity, host, description, url, module)
            # Restore cursor position if possible
            if old_cursor < vulns_table.row_count:
                vulns_table.move_cursor(row=old_cursor)
        except:
            pass

        # Refresh findings table
        try:
            findings_table = self.query_one("#findings-table", FindingsTable)
            old_cursor = findings_table.cursor_row
            findings_table.findings = [
                e for e in self.scan_data.events
                if e.get("type") == "FINDING"
            ]
            findings_table.clear()

            # Limit to MAX_DISPLAY_ROWS for performance
            display_findings = findings_table.findings[:findings_table.MAX_DISPLAY_ROWS]

            for finding in display_findings:
                from rich.text import Text
                data = finding.get("data", {})
                host = data.get("host", "")
                # Use Text() to treat content as plain text (no markup interpretation)
                description = Text(data.get("description", "")[:70], no_wrap=True, overflow="ellipsis")
                url = Text(data.get("url", "")[:40], no_wrap=True, overflow="ellipsis")
                module = finding.get("module", "")
                findings_table.add_row(host, description, url, module)
            # Restore cursor position if possible
            if old_cursor < findings_table.row_count:
                findings_table.move_cursor(row=old_cursor)
        except:
            pass

        try:
            # Refresh event table
            event_table = self.query_one("#event-table", EventTable)
            event_table.refresh_table(self.current_type_filter, self.current_scope_filter)
        except:
            pass

        try:
            # Refresh tree view
            tree = self.query_one("#discovery-tree", DiscoveryTree)
            tree.rebuild_tree(self.tree_type_filter, self.tree_scope_filter)
        except:
            pass

        # Update event type filter options (in case new event types appeared)
        try:
            event_types = ["All"] + sorted(
                list(set(e.get("type", "") for e in self.scan_data.events))
            )
            type_filter = self.query_one("#event-type-filter", Select)
            current_value = type_filter.value
            type_filter.set_options([(t, t) for t in event_types])
            if current_value in event_types:
                type_filter.value = current_value

            tree_type_filter = self.query_one("#tree-type-filter", Select)
            current_tree_value = tree_type_filter.value
            tree_type_filter.set_options([(t, t) for t in event_types])
            if current_tree_value in event_types:
                tree_type_filter.value = current_tree_value
        except:
            pass

        try:
            # Refresh statistics view
            # Note: We need to find the StatisticsView widget in the stats-tab
            # The StatisticsView is a direct child of the TabPane, so we need to query for it
            stats_view = self.query_one(StatisticsView)
            stats_view.refresh_statistics()
        except:
            pass

    def action_refresh_scan(self) -> None:
        """Manually trigger a scan refresh"""
        new_event_count = self.scan_data.load_new_events()
        if new_event_count > 0:
            self.total_events = len(self.scan_data.events)
            self.scan_status = self.scan_data.get_scan_status()
            self.refresh_ui_components()
            self.notify(f"Loaded {new_event_count} new events", timeout=2)
        else:
            # Update status even if no new events
            self.scan_status = self.scan_data.get_scan_status()
            self.notify("No new events", timeout=2)

    def on_data_table_row_highlighted(self, event: DataTable.RowHighlighted) -> None:
        """Handle row highlight (navigation) in tables"""
        # Check which table triggered the event
        if event.data_table.id == "vulnerabilities-table":
            table = self.query_one("#vulnerabilities-table", VulnerabilitiesTable)
            row_index = event.cursor_row

            if row_index < len(table.vulnerabilities):
                selected_vuln = table.vulnerabilities[row_index]
                detail_view = self.query_one("#vulnerability-detail", FindingDetailView)
                detail_view.finding_json = selected_vuln

        elif event.data_table.id == "findings-table":
            table = self.query_one("#findings-table", FindingsTable)
            row_index = event.cursor_row

            if row_index < len(table.findings):
                selected_finding = table.findings[row_index]
                detail_view = self.query_one("#finding-detail", FindingDetailView)
                detail_view.finding_json = selected_finding

        elif event.data_table.id == "event-table":
            table = self.query_one("#event-table", EventTable)
            row_index = event.cursor_row

            if row_index < len(table.filtered_events):
                selected_event = table.filtered_events[row_index]
                detail_view = self.query_one("#event-detail", EventDetailView)
                detail_view.event_json = selected_event

    def on_tree_node_highlighted(self, event: Tree.NodeHighlighted) -> None:
        """Handle tree node highlight (navigation)"""
        node = event.node
        if node.data:  # Node has event data attached
            detail_view = self.query_one("#tree-detail", TreeDetailView)
            detail_view.event_json = node.data

    def on_select_changed(self, event: Select.Changed) -> None:
        """Handle filter selection change"""
        if event.select.id == "event-type-filter":
            self.current_type_filter = event.value
            table = self.query_one("#event-table", EventTable)
            table.refresh_table(self.current_type_filter, self.current_scope_filter)
        elif event.select.id == "tree-mode-select":
            tree = self.query_one("#discovery-tree", DiscoveryTree)
            tree.switch_mode(event.value)
        elif event.select.id == "tree-type-filter":
            self.tree_type_filter = event.value
            tree = self.query_one("#discovery-tree", DiscoveryTree)
            tree.rebuild_tree(self.tree_type_filter, self.tree_scope_filter)

    def _match_search_term(self, event: Dict[str, Any], term: str) -> bool:
        """Check if a single search term matches any field in the event"""
        term_lower = term.lower()

        # Fields to search
        searchable_fields = [
            str(event.get("data", "")),
            str(event.get("type", "")),
            str(event.get("module", "")),
            str(event.get("host", "")),
            str(event.get("discovery_context", "")),
        ]

        # Add all tags
        for tag in event.get("tags", []):
            searchable_fields.append(str(tag))

        # Check if term appears in any field
        return any(term_lower in field.lower() for field in searchable_fields)

    def on_input_changed(self, event: Input.Changed) -> None:
        """Handle search input with multi-term support"""
        if event.input.id == "search-input":
            search_input = event.value.strip()
            table = self.query_one("#event-table", EventTable)

            if search_input:
                # Split by whitespace to get multiple search terms
                search_terms = search_input.split()

                # Filter: event matches if ALL terms match (AND logic)
                table.filtered_events = [
                    e
                    for e in table.scan_data.events
                    if all(self._match_search_term(e, term) for term in search_terms)
                ]
            else:
                table.filtered_events = table.scan_data.events

            table.clear()
            for evt in table.filtered_events[:1000]:
                event_type = evt.get("type", "")
                data = str(evt.get("data", ""))[:50]
                module = evt.get("module", "")
                scope = str(evt.get("scope_distance", ""))
                timestamp = str(evt.get("timestamp", ""))[:10]
                table.add_row(event_type, data, module, scope, timestamp)
        elif event.input.id == "scope-distance-input":
            value = event.value.strip()
            if value and value.isdigit():
                self.current_scope_filter = int(value)
            else:
                self.current_scope_filter = None  # "all"
            table = self.query_one("#event-table", EventTable)
            table.refresh_table(self.current_type_filter, self.current_scope_filter)
        elif event.input.id == "tree-scope-input":
            value = event.value.strip()
            if value and value.isdigit():
                self.tree_scope_filter = int(value)
            else:
                self.tree_scope_filter = None  # "all"
            tree = self.query_one("#discovery-tree", DiscoveryTree)
            tree.rebuild_tree(self.tree_type_filter, self.tree_scope_filter)

    def action_focus_filter(self) -> None:
        """Focus the search input"""
        self.query_one("#search-input", Input).focus()

    def action_quit_viewer(self) -> None:
        """Return to scan list"""
        self.app.pop_screen()

    def action_adjust_split_left(self) -> None:
        """Decrease main panel width (increase detail panel)"""
        if self.split_ratio > 30:
            self.split_ratio -= 5
            self.update_split()

    def action_adjust_split_right(self) -> None:
        """Increase main panel width (decrease detail panel)"""
        if self.split_ratio < 80:
            self.split_ratio += 5
            self.update_split()

    def update_split(self) -> None:
        """Update the split ratio dynamically"""
        # Update findings pane
        try:
            findings_container = self.query_one("#findings-container")
            findings_container.styles.width = f"{self.split_ratio}%"

            detail_container = self.query_one("#finding-detail-container")
            detail_container.styles.width = f"{100 - self.split_ratio}%"
        except:
            pass

        # Update events pane
        try:
            main_container = self.query_one("#main-container")
            main_container.styles.width = f"{self.split_ratio}%"

            event_detail = self.query_one("#detail-container")
            event_detail.styles.width = f"{100 - self.split_ratio}%"
        except:
            pass

        # Update tree pane
        try:
            tree_container = self.query_one("#tree-container")
            tree_container.styles.width = f"{self.split_ratio}%"

            tree_detail = self.query_one("#tree-detail-container")
            tree_detail.styles.width = f"{100 - self.split_ratio}%"
        except:
            pass


class BBotViewer(App):
    """Main BBOT TUI application"""

    CSS = """
    #live-status {
        height: 1;
        padding: 0 1;
        background: $panel;
        text-align: center;
    }

    #findings-pane {
        layout: horizontal;
    }

    #findings-container {
        width: 60%;
        height: 100%;
    }

    #findings-filter-container {
        height: auto;
        padding: 1;
        background: $panel;
    }

    #findings-severity-col {
        height: auto;
        width: auto;
        margin-right: 2;
    }

    #severity-filter {
        width: 20;
    }

    #finding-detail-container {
        width: 40%;
        height: 100%;
        border-left: solid $accent;
    }

    FindingsTable {
        height: 1fr;
    }

    FindingDetailView {
        height: 100%;
        overflow-y: auto;
        padding: 1;
    }

    #events-pane {
        layout: horizontal;
    }

    #main-container {
        width: 60%;
        height: 100%;
    }

    #detail-container {
        width: 40%;
        height: 100%;
        border-left: solid $accent;
    }

    #filter-container {
        height: auto;
        padding: 1;
        background: $panel;
    }

    #event-type-col {
        height: auto;
        width: auto;
        margin-right: 2;
    }

    #event-type-filter {
        width: 20;
    }

    #event-scope-col {
        height: auto;
        width: auto;
        margin-right: 2;
    }

    #scope-distance-input {
        width: 15;
    }

    #event-search-col {
        height: auto;
        width: 1fr;
    }

    #search-input {
        width: 1fr;
    }

    EventTable {
        height: 1fr;
    }

    EventDetailView {
        height: 100%;
        overflow-y: auto;
    }

    #tree-pane {
        layout: horizontal;
    }

    #tree-container {
        width: 60%;
        height: 100%;
    }

    #tree-filter-container {
        height: auto;
        padding: 1;
        background: $panel;
    }

    #tree-mode-col {
        height: auto;
        width: auto;
        margin-right: 2;
    }

    #tree-mode-select {
        width: 20;
    }

    #tree-type-col {
        height: auto;
        width: auto;
        margin-right: 2;
    }

    #tree-type-filter {
        width: 20;
    }

    #tree-scope-col {
        height: auto;
        width: auto;
    }

    #tree-scope-input {
        width: 15;
    }

    #tree-detail-container {
        width: 40%;
        height: 100%;
        border-left: solid $accent;
    }

    DiscoveryTree {
        height: 1fr;
    }

    TreeDetailView {
        height: 100%;
        overflow-y: auto;
        padding: 1;
    }

    StatisticsView {
        padding: 1;
        overflow-y: auto;
    }

    PresetView {
        width: 100%;
        height: 100%;
        overflow-y: auto;
    }

    #scan-table {
        height: 1fr;
    }

    #header {
        padding: 1;
        background: $panel;
    }

    #archive-header {
        padding: 1;
        background: $panel;
    }

    #archive-table {
        height: 1fr;
    }

    #dialog {
        align: center middle;
        width: 60;
        height: auto;
        padding: 2;
        background: $panel;
        border: thick $accent;
    }

    #dialog-message {
        width: 100%;
        height: auto;
        margin-bottom: 1;
        text-align: center;
    }

    #dialog-buttons {
        width: 100%;
        height: auto;
        align: center middle;
    }

    #dialog-buttons Button {
        margin: 0 1;
    }
    """

    BINDINGS = [
        Binding("q", "quit", "Quit", priority=True),
    ]

    def __init__(self, path: Path, scan_refresh_interval: float = None, list_refresh_interval: float = None):
        super().__init__()
        self.path = path
        self.is_directory = path.is_dir() and (path / "output.json").exists() == False
        self.config_file = Path.home() / ".bbot_ui_config.json"

        # Load config and apply defaults
        config = self.load_config()

        # Refresh intervals (in seconds)
        self.scan_refresh_interval = scan_refresh_interval if scan_refresh_interval is not None else config.get('scan_refresh_interval', 2.0)
        self.list_refresh_interval = list_refresh_interval if list_refresh_interval is not None else config.get('list_refresh_interval', 3.0)

        # Save to config if changed from defaults
        if scan_refresh_interval is not None or list_refresh_interval is not None:
            config['scan_refresh_interval'] = self.scan_refresh_interval
            config['list_refresh_interval'] = self.list_refresh_interval
            self.save_config(config)

    def load_config(self) -> dict:
        """Load saved configuration"""
        if self.config_file.exists():
            try:
                with open(self.config_file, 'r') as f:
                    return json.load(f)
            except:
                return {}
        return {}

    def save_config(self, config: dict) -> None:
        """Save configuration"""
        try:
            with open(self.config_file, 'w') as f:
                json.dump(config, f, indent=2)
        except:
            pass

    def watch_theme(self, theme: str) -> None:
        """Called when theme changes - save the new theme"""
        config = self.load_config()
        config['theme'] = theme
        self.save_config(config)

    def on_mount(self) -> None:
        """Set up the application"""
        # Load and apply saved theme
        config = self.load_config()
        if 'theme' in config:
            self.theme = config['theme']

        if self.is_directory:
            # Show scan list
            self.title = "BBOT TUI - Scan Manager"
            self.push_screen(ScanListScreen(self.path, self.list_refresh_interval))
        else:
            # Show single scan directly
            self.title = f"BBOT TUI - {self.path.name}"
            self.push_screen(ScanViewerScreen(self.path, self.scan_refresh_interval))


def main():
    """Main entry point"""
    import argparse

    parser = argparse.ArgumentParser(
        description="BBOT TUI - Terminal interface for browsing BBOT scan results with live refresh",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s                                    # Use default path (~/.bbot/scans)
  %(prog)s /path/to/scans                     # Browse all scans in directory
  %(prog)s ~/.bbot/scans/example.com          # View specific scan
  %(prog)s --scan-interval 5 --list-interval 10  # Slower refresh rates

Configuration is saved to ~/.bbot_ui_config.json
        """
    )

    parser.add_argument(
        'path',
        nargs='?',
        default=None,
        help='Path to scan directory or parent scans directory (default: ~/.bbot/scans)'
    )

    parser.add_argument(
        '--scan-interval',
        type=float,
        metavar='SECONDS',
        help='Refresh interval for scan detail view in seconds (default: 2.0)'
    )

    parser.add_argument(
        '--list-interval',
        type=float,
        metavar='SECONDS',
        help='Refresh interval for scan list view in seconds (default: 3.0)'
    )

    args = parser.parse_args()

    # Determine path
    if args.path:
        path = Path(args.path).expanduser()
    else:
        path = Path("~/.bbot/scans").expanduser()
        print(f"No path specified, using default: {path}")

    if not path.exists():
        print(f"Error: Path not found: {path}")
        sys.exit(1)

    if not path.is_dir():
        print(f"Error: Path must be a directory: {path}")
        sys.exit(1)

    # Check if it's a single scan directory or a parent scans directory
    has_output_json = (path / "output.json").exists()

    if not has_output_json:
        # Check if it contains scan subdirectories
        scan_dirs = [d for d in path.iterdir() if d.is_dir() and (d / "output.json").exists()]
        if not scan_dirs:
            print(f"Error: No scan directories found in {path}")
            print("Looking for directories containing output.json files")
            sys.exit(1)

    # Check if psutil is available (required for accurate status detection)
    try:
        import psutil
    except ImportError:
        print("\nâš ï¸  WARNING: psutil is not installed in your virtual environment", file=sys.stderr)
        print("   This is required for accurate scan status detection (RUNNING vs INTERRUPTED).", file=sys.stderr)
        print("   Scans may show as RUNNING when they are actually INTERRUPTED.\n", file=sys.stderr)
        print("   To fix this, reinstall the virtual environment:", file=sys.stderr)
        print("   rm -rf ~/.bbot_ui_venv && ./bbot-ui\n", file=sys.stderr)
        import time
        time.sleep(3)  # Give user time to read the warning

    app = BBotViewer(
        path,
        scan_refresh_interval=args.scan_interval,
        list_refresh_interval=args.list_interval
    )
    app.run()


if __name__ == "__main__":
    main()
